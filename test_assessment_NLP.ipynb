{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41ec0e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from IPython.display import display\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d9e746f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>As a term, data analytics predominantly refers to an assortment of applications, from basic business intelligence (BI), reporting and online analytical processing (OLAP) to various forms of advanced analytics. In that sense, it's similar in nature to business analytics, another umbrella term for approaches to analyzing data -- with the difference that the latter is oriented to business uses, while data analytics has a broader focus. The expansive view of the term isn't universal, though: In some cases, people use data analytics specifically to mean advanced analytics, treating BI as a separate category. Data analytics initiatives can help businesses increase revenues, improve operational efficiency, optimize marketing campaigns and customer service efforts, respond more quickly to emerging market trends and gain a competitive edge over rivals -- all with the ultimate goal of boosting business performance. Depending on the particular application, the data that's analyzed can consist of either historical records or new information that has been processed for real-time analytics uses. In addition, it can come from a mix of internal systems and external data sources. At a high level, data analytics methodologies include exploratory data analysis (EDA), which aims to find patterns and relationships in data, and confirmatory data analysis (CDA), which applies statistical techniques to determine whether hypotheses about a data set are true or false. EDA is often compared to detective work, while CDA is akin to the work of a judge or jury during a court trial -- a distinction first drawn by statistician John W. Tukey in his 1977 book Exploratory Data Analysis. Data analytics can also be separated into quantitative data analysis and qualitative data analysis. The former involves analysis of numerical data with quantifiable variables that can be compared or measured statistically. The qualitative approach is more interpretive -- it focuses on understanding the content of non-numerical data like text, images, audio and video, including common phrases, themes and points of view.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [As a term, data analytics predominantly refers to an assortment of applications, from basic business intelligence (BI), reporting and online analytical processing (OLAP) to various forms of advanced analytics. In that sense, it's similar in nature to business analytics, another umbrella term for approaches to analyzing data -- with the difference that the latter is oriented to business uses, while data analytics has a broader focus. The expansive view of the term isn't universal, though: In some cases, people use data analytics specifically to mean advanced analytics, treating BI as a separate category. Data analytics initiatives can help businesses increase revenues, improve operational efficiency, optimize marketing campaigns and customer service efforts, respond more quickly to emerging market trends and gain a competitive edge over rivals -- all with the ultimate goal of boosting business performance. Depending on the particular application, the data that's analyzed can consist of either historical records or new information that has been processed for real-time analytics uses. In addition, it can come from a mix of internal systems and external data sources. At a high level, data analytics methodologies include exploratory data analysis (EDA), which aims to find patterns and relationships in data, and confirmatory data analysis (CDA), which applies statistical techniques to determine whether hypotheses about a data set are true or false. EDA is often compared to detective work, while CDA is akin to the work of a judge or jury during a court trial -- a distinction first drawn by statistician John W. Tukey in his 1977 book Exploratory Data Analysis. Data analytics can also be separated into quantitative data analysis and qualitative data analysis. The former involves analysis of numerical data with quantifiable variables that can be compared or measured statistically. The qualitative approach is more interpretive -- it focuses on understanding the content of non-numerical data like text, images, audio and video, including common phrases, themes and points of view.]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('test_assessment.txt', delimiter='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71603984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a term, data analytics predominantly refers to an assortment of applications, from basic business intelligence (BI), reporting and online analytical processing (OLAP) to various forms of advanced analytics. In that sense, it's similar in nature to business analytics, another umbrella term for approaches to analyzing data -- with the difference that the latter is oriented to business uses, while data analytics has a broader focus. The expansive view of the term isn't universal, though: In some cases, people use data analytics specifically to mean advanced analytics, treating BI as a separate category. Data analytics initiatives can help businesses increase revenues, improve operational efficiency, optimize marketing campaigns and customer service efforts, respond more quickly to emerging market trends and gain a competitive edge over rivals -- all with the ultimate goal of boosting business performance. Depending on the particular application, the data that's analyzed can consist of either historical records or new information that has been processed for real-time analytics uses. In addition, it can come from a mix of internal systems and external data sources. At a high level, data analytics methodologies include exploratory data analysis (EDA), which aims to find patterns and relationships in data, and confirmatory data analysis (CDA), which applies statistical techniques to determine whether hypotheses about a data set are true or false. EDA is often compared to detective work, while CDA is akin to the work of a judge or jury during a court trial -- a distinction first drawn by statistician John W. Tukey in his 1977 book Exploratory Data Analysis. Data analytics can also be separated into quantitative data analysis and qualitative data analysis. The former involves analysis of numerical data with quantifiable variables that can be compared or measured statistically. The qualitative approach is more interpretive -- it focuses on understanding the content of non-numerical data like text, images, audio and video, including common phrases, themes and points of view.\n"
     ]
    }
   ],
   "source": [
    "# Open the text file in read mode\n",
    "with open('test_assessment.txt', 'r') as file:\n",
    "    # Read the entire file content\n",
    "    txt = file.read()\n",
    "\n",
    "# Print the content\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ba3a4",
   "metadata": {},
   "source": [
    "# Text-Processing - tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6dd40e4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\looi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\looi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\looi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\looi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\looi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "285bdbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(txt):\n",
    "    cleaned = txt\n",
    "    # Remove the named entities\n",
    "    name_entities_to_remove = [r'hotels?', r'rooms?', r\"[Bb]&[Bb]'?s?\"]\n",
    "    for entity in name_entities_to_remove:\n",
    "        # Use a non-letter before and after the entity to ensure whole-word matching\n",
    "        #df_cols['review_text'] = df_cols['review_text'].astype(str).str.replace(f\" {entity} \", \" \")\n",
    "        cleaned = re.sub(r'[^\\w]' + entity + r'[^\\w]', ' ', cleaned)\n",
    "    \n",
    "    #remove urls\n",
    "    cleaned=re.sub(r'http\\S+',' ',cleaned)\n",
    "    #remove hashtags and word after hashtag\n",
    "    cleaned=re.sub(r'#([^\\s]+)',' ',cleaned)\n",
    "    #remove emojis\n",
    "    emoji=re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u'\\U00010000-\\U0010ffff'\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\u3030\"\n",
    "        u\"\\ufe0f\"\n",
    "                     \"]+\", flags = re.UNICODE)\n",
    "    cleaned=emoji.sub(r'',cleaned)\n",
    "    #remove punctuations and special characters\n",
    "    cleaned=re.sub(r'[^\\w\\s]',' ',cleaned)\n",
    "    cleaned=\"\".join([c for c in cleaned if c not in string.punctuation])\n",
    "    #remove numbers\n",
    "    cleaned=re.sub('[0-9]+',' ',cleaned)\n",
    "    #remove single character\n",
    "    cleaned=re.sub(r'\\s+[a-zA-Z]\\s+',' ',cleaned)\n",
    "    #to lower case\n",
    "    cleaned=cleaned.lower()\n",
    "    #remove newlines, multiple space\n",
    "    cleaned=re.sub(r'\\s+',' ',cleaned)\n",
    "    #tokenized\n",
    "    cleaned=cleaned.split()\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b47de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['as', 'term', 'data', 'analytics', 'predominantly', 'refers', 'to', 'an', 'assortment', 'of', 'applications', 'from', 'basic', 'business', 'intelligence', 'bi', 'reporting', 'and', 'online', 'analytical', 'processing', 'olap', 'to', 'various', 'forms', 'of', 'advanced', 'analytics', 'in', 'that', 'sense', 'it', 'similar', 'in', 'nature', 'to', 'business', 'analytics', 'another', 'umbrella', 'term', 'for', 'approaches', 'to', 'analyzing', 'data', 'with', 'the', 'difference', 'that', 'the', 'latter', 'is', 'oriented', 'to', 'business', 'uses', 'while', 'data', 'analytics', 'has', 'broader', 'focus', 'the', 'expansive', 'view', 'of', 'the', 'term', 'isn', 'universal', 'though', 'in', 'some', 'cases', 'people', 'use', 'data', 'analytics', 'specifically', 'to', 'mean', 'advanced', 'analytics', 'treating', 'bi', 'as', 'separate', 'category', 'data', 'analytics', 'initiatives', 'can', 'help', 'businesses', 'increase', 'revenues', 'improve', 'operational', 'efficiency', 'optimize', 'marketing', 'campaigns', 'and', 'customer', 'service', 'efforts', 'respond', 'more', 'quickly', 'to', 'emerging', 'market', 'trends', 'and', 'gain', 'competitive', 'edge', 'over', 'rivals', 'all', 'with', 'the', 'ultimate', 'goal', 'of', 'boosting', 'business', 'performance', 'depending', 'on', 'the', 'particular', 'application', 'the', 'data', 'that', 'analyzed', 'can', 'consist', 'of', 'either', 'historical', 'records', 'or', 'new', 'information', 'that', 'has', 'been', 'processed', 'for', 'real', 'time', 'analytics', 'uses', 'in', 'addition', 'it', 'can', 'come', 'from', 'mix', 'of', 'internal', 'systems', 'and', 'external', 'data', 'sources', 'at', 'high', 'level', 'data', 'analytics', 'methodologies', 'include', 'exploratory', 'data', 'analysis', 'eda', 'which', 'aims', 'to', 'find', 'patterns', 'and', 'relationships', 'in', 'data', 'and', 'confirmatory', 'data', 'analysis', 'cda', 'which', 'applies', 'statistical', 'techniques', 'to', 'determine', 'whether', 'hypotheses', 'about', 'data', 'set', 'are', 'true', 'or', 'false', 'eda', 'is', 'often', 'compared', 'to', 'detective', 'work', 'while', 'cda', 'is', 'akin', 'to', 'the', 'work', 'of', 'judge', 'or', 'jury', 'during', 'court', 'trial', 'distinction', 'first', 'drawn', 'by', 'statistician', 'john', 'tukey', 'in', 'his', 'book', 'exploratory', 'data', 'analysis', 'data', 'analytics', 'can', 'also', 'be', 'separated', 'into', 'quantitative', 'data', 'analysis', 'and', 'qualitative', 'data', 'analysis', 'the', 'former', 'involves', 'analysis', 'of', 'numerical', 'data', 'with', 'quantifiable', 'variables', 'that', 'can', 'be', 'compared', 'or', 'measured', 'statistically', 'the', 'qualitative', 'approach', 'is', 'more', 'interpretive', 'it', 'focuses', 'on', 'understanding', 'the', 'content', 'of', 'non', 'numerical', 'data', 'like', 'text', 'images', 'audio', 'and', 'video', 'including', 'common', 'phrases', 'themes', 'and', 'points', 'of', 'view']\n"
     ]
    }
   ],
   "source": [
    "txt_preprocessed = preprocess(txt)\n",
    "print(txt_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4c523c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baa1be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: 18\n",
      "to: 11\n",
      "the: 11\n",
      "analytics: 10\n",
      "of: 10\n",
      "and: 9\n",
      "in: 6\n",
      "analysis: 6\n",
      "that: 5\n",
      "can: 5\n",
      "business: 4\n",
      "is: 4\n",
      "or: 4\n",
      "term: 3\n",
      "it: 3\n",
      "with: 3\n",
      "as: 2\n",
      "from: 2\n",
      "bi: 2\n",
      "advanced: 2\n",
      "for: 2\n",
      "uses: 2\n",
      "while: 2\n",
      "has: 2\n",
      "view: 2\n",
      "more: 2\n",
      "on: 2\n",
      "exploratory: 2\n",
      "eda: 2\n",
      "which: 2\n",
      "cda: 2\n",
      "compared: 2\n",
      "work: 2\n",
      "be: 2\n",
      "qualitative: 2\n",
      "numerical: 2\n",
      "predominantly: 1\n",
      "refers: 1\n",
      "an: 1\n",
      "assortment: 1\n",
      "applications: 1\n",
      "basic: 1\n",
      "intelligence: 1\n",
      "reporting: 1\n",
      "online: 1\n",
      "analytical: 1\n",
      "processing: 1\n",
      "olap: 1\n",
      "various: 1\n",
      "forms: 1\n",
      "sense: 1\n",
      "similar: 1\n",
      "nature: 1\n",
      "another: 1\n",
      "umbrella: 1\n",
      "approaches: 1\n",
      "analyzing: 1\n",
      "difference: 1\n",
      "latter: 1\n",
      "oriented: 1\n",
      "broader: 1\n",
      "focus: 1\n",
      "expansive: 1\n",
      "isn: 1\n",
      "universal: 1\n",
      "though: 1\n",
      "some: 1\n",
      "cases: 1\n",
      "people: 1\n",
      "use: 1\n",
      "specifically: 1\n",
      "mean: 1\n",
      "treating: 1\n",
      "separate: 1\n",
      "category: 1\n",
      "initiatives: 1\n",
      "help: 1\n",
      "businesses: 1\n",
      "increase: 1\n",
      "revenues: 1\n",
      "improve: 1\n",
      "operational: 1\n",
      "efficiency: 1\n",
      "optimize: 1\n",
      "marketing: 1\n",
      "campaigns: 1\n",
      "customer: 1\n",
      "service: 1\n",
      "efforts: 1\n",
      "respond: 1\n",
      "quickly: 1\n",
      "emerging: 1\n",
      "market: 1\n",
      "trends: 1\n",
      "gain: 1\n",
      "competitive: 1\n",
      "edge: 1\n",
      "over: 1\n",
      "rivals: 1\n",
      "all: 1\n",
      "ultimate: 1\n",
      "goal: 1\n",
      "boosting: 1\n",
      "performance: 1\n",
      "depending: 1\n",
      "particular: 1\n",
      "application: 1\n",
      "analyzed: 1\n",
      "consist: 1\n",
      "either: 1\n",
      "historical: 1\n",
      "records: 1\n",
      "new: 1\n",
      "information: 1\n",
      "been: 1\n",
      "processed: 1\n",
      "real: 1\n",
      "time: 1\n",
      "addition: 1\n",
      "come: 1\n",
      "mix: 1\n",
      "internal: 1\n",
      "systems: 1\n",
      "external: 1\n",
      "sources: 1\n",
      "at: 1\n",
      "high: 1\n",
      "level: 1\n",
      "methodologies: 1\n",
      "include: 1\n",
      "aims: 1\n",
      "find: 1\n",
      "patterns: 1\n",
      "relationships: 1\n",
      "confirmatory: 1\n",
      "applies: 1\n",
      "statistical: 1\n",
      "techniques: 1\n",
      "determine: 1\n",
      "whether: 1\n",
      "hypotheses: 1\n",
      "about: 1\n",
      "set: 1\n",
      "are: 1\n",
      "true: 1\n",
      "false: 1\n",
      "often: 1\n",
      "detective: 1\n",
      "akin: 1\n",
      "judge: 1\n",
      "jury: 1\n",
      "during: 1\n",
      "court: 1\n",
      "trial: 1\n",
      "distinction: 1\n",
      "first: 1\n",
      "drawn: 1\n",
      "by: 1\n",
      "statistician: 1\n",
      "john: 1\n",
      "tukey: 1\n",
      "his: 1\n",
      "book: 1\n",
      "also: 1\n",
      "separated: 1\n",
      "into: 1\n",
      "quantitative: 1\n",
      "former: 1\n",
      "involves: 1\n",
      "quantifiable: 1\n",
      "variables: 1\n",
      "measured: 1\n",
      "statistically: 1\n",
      "approach: 1\n",
      "interpretive: 1\n",
      "focuses: 1\n",
      "understanding: 1\n",
      "content: 1\n",
      "non: 1\n",
      "like: 1\n",
      "text: 1\n",
      "images: 1\n",
      "audio: 1\n",
      "video: 1\n",
      "including: 1\n",
      "common: 1\n",
      "phrases: 1\n",
      "themes: 1\n",
      "points: 1\n"
     ]
    }
   ],
   "source": [
    "word_counts = Counter(txt_preprocessed)\n",
    "sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for word, count in sorted_word_counts:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b268af02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0410958904109589]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a. What is the probability of the word “data” occurring in each line ?\n",
    "#the question doesn't require the sentences to be tokenized into singular wording\n",
    "\n",
    "line_probabilities = []\n",
    "for line in txt.splitlines():\n",
    "    line_tokens = word_tokenize(line)\n",
    "    line_prob = line_tokens.count(\"data\") / len(line_tokens)\n",
    "    line_probabilities.append(line_prob)\n",
    "    \n",
    "line_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64abb027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({204: 1})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b. What is the distribution of distinct word counts across all the lines ?\n",
    "#unable to figure out_need more time for researching\n",
    "distinct_word_counts = [len(set(word_tokenize(line))) for line in txt.splitlines()]\n",
    "distinct_word_counts_freq = FreqDist(distinct_word_counts)\n",
    "\n",
    "distinct_word_counts_freq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10d26f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26666666666666666"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c. What is the probability of the word “analytics” occurring after the word “data” ?\n",
    "# Count the occurrences of \"data\" followed by \"analytics\"\n",
    "# ngram\n",
    "\n",
    "data_analytics_count = sum(1 for _ in ngrams(tokens, 2) if 'data' in _ and 'analytics' in _)\n",
    "data_count = tokens.count('data')\n",
    "analytics_after_data_prob = data_analytics_count / data_count if data_count > 0 else 0\n",
    "\n",
    "analytics_after_data_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477c2a0",
   "metadata": {},
   "source": [
    "References \n",
    "1. https://blog.devgenius.io/using-nltk-frequency-distribution-and-conditional-frequency-distribution-to-identify-the-most-8b2f11f6743f\n",
    "2. https://pabasar.medium.com/checking-the-frequency-distribution-of-words-and-letters-of-a-content-using-nltk-8ac35e4fa4a0\n",
    "3. https://codereview.stackexchange.com/questions/167027/calculate-probability-of-word-occurence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
